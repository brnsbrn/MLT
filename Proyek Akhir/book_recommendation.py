# -*- coding: utf-8 -*-
"""Book Recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tjT-lAVglELpI-5McNyOj0OV8XP8OLk8

Mengimpor Modul
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt

"""Mengunduh dataset menggunakan kredensial kaggle"""

!chmod 600 /content/kaggle.json

!KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d arashnic/book-recommendation-dataset

"""Ekstrak Zip Dataset"""

import zipfile, os
local_zip = '/content/book-recommendation-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/Books Recommendation')
zip_ref.close()

"""Gunakan dataframe Books dan Ratings"""

book = pd.read_csv('/content/Books Recommendation/Books.csv')
rating = pd.read_csv('/content/Books Recommendation/Ratings.csv')

"""Melihat ukuran kedua dataframe"""

book.shape

rating.shape

"""Melihat info kedua dataframe"""

book.info()

book = book.rename(columns={'Book-Title': 'title','Book-Author':'author', 'Year-Of-Publication' : 'year'})

print('Banyak buku: ', len(book.title.unique()))
print('Tahun Terbit: ', book.year.unique())

rating.info()

rating = rating.rename(columns={'Book-Rating': 'rating','User-ID':'user_id'})

print('Banyak data: ', len(rating.user_id.unique()))
print('Angka Rating: ', rating.rating.unique())

"""# Data Prepocessing

Mengambil 10000 data di book dan 5000 di rating, karena data terlalu banyak
"""

book = book[:10000]
rating = rating[:5000]

"""Melihat id buku mana yang mendapat rate 10"""

rating[rating.rating == max(rating.rating)]
best_id = rating.ISBN[rating.rating == max(rating.rating)]
best_id = list(dict.fromkeys(best_id))

"""Judul buku mana yang mendapat rating 10"""

best_books = []
for i in best_id:
    books_name = book.title[book.ISBN == i]
    best_books.append(books_name)

best_books

len(best_books)

"""# Content Based Filtering

## Data Preparation

Mendrop seluruh kolom yang mengandung Na/Null di book dan Rating
"""

book = book.dropna()
rating = rating.dropna()

"""Mengdrop baris yang menduplikasi baris yang lain agar data tidak tumpang tindih dan tidak berulang-ulang"""

book = book.drop_duplicates()
rating = rating.drop_duplicates()

book.head()

"""Mengubah dataframe book menjadi list"""

book_ISBN = book['ISBN'].tolist()

book_title = book['title'].tolist()

book_author = book['author'].tolist()

book_year_of_publication = book['year'].tolist()

"""Buat dictionary untuk menentukan key value dari list yang telah kita buat"""

new_book = pd.DataFrame({
    'book_ISBN': book_ISBN,
    'book_title': book_title,
    'book_author': book_author,
    'book_year_of_publication': book_year_of_publication
})
new_book

"""## Modelling

Modelling menggunakan fungsi tfidfvectorizer() dari library sklearn.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
tf = TfidfVectorizer()
tf.fit(new_book['book_author']) 
tf.get_feature_names()

"""Lakukan fit transformasi dalam bentuk matriks"""

tfidf_matrix = tf.fit_transform(new_book['book_author']) 
 
tfidf_matrix.shape

"""Untuk menghasilkan vektor tf-idf dalam bentuk matriks, gunakan fungsi todense()"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=new_book.book_title
).sample(10, axis=1,replace=True).sample(10, axis=0)

"""Hitung derajat kesamaan (similarity degree) antar buku dengan teknik cosine similarity. Di sini, kita menggunakan fungsi cosine_similarity dari library sklearn"""

from sklearn.metrics.pairwise import cosine_similarity
 
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Buat dataframe cosine dengan kolom dan baris merupakan judul buku"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=new_book['book_title'], columns=new_book['book_title'])

"""Membuat fungsi 5 rekomendasi teratas berdasarkan item"""

def author_recommendations(i, M, items, k=5):
    ix = M.loc[:,i].to_numpy().argpartition(range(-1,-k,-1))
    closest = M.columns[ix[-1:-(k+2):-1]]
    closest = closest.drop(i, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

new_book

"""Membuat item buku yang sudah dibaca agar dapat membuat rekomendasi berdasarkan item tersebut.

"""

item_book = 'The Star Rover'
new_book[new_book.book_title.eq(item_book)]

"""Membuat rekomendasi berdasarkan item_books"""

recommendations = author_recommendations(item_book, cosine_sim_df, new_book[['book_title', 'book_author']])

recommendations = recommendations.drop_duplicates()

recommendations

"""## Evaluasi

Menggunakan matriks akurasi
"""

books_that_have_been_read_row = book[book.title == item_book]
books_that_have_been_read_author = books_that_have_been_read_row.iloc[0]["author"]

book_recommendation_authors = recommendations.book_author

real_author = 0
for i in range(5):
    if book_recommendation_authors[i] == books_that_have_been_read_author:
        real_author+=1

Accuracy = real_author/5*100
print("Accuracy of the model is {}%".format(Accuracy))

"""# Collaborative Filter

## Data Preparation

Encoding kolom user_id menjadi integer
"""

user_ids = rating['user_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Encoding kolom ISBN menjadi integer"""

book_ids = rating['ISBN'].unique().tolist()
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}
print('encoded ISBN: ', book_to_book_encoded)
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}
print('encoded angka ke ISBN: ', book_encoded_to_book)

rating['user'] = rating['user_id'].map(user_to_user_encoded)
rating['book'] = rating['ISBN'].map(book_to_book_encoded)

"""Cek beberapa hal dalam data seperti jumlah user, jumlah jumlah buku, dan mengubah nilai rating menjadi float."""

num_users = len(user_encoded_to_user)
print(num_users)
num_book = len(book_encoded_to_book)
print(num_book)
rating['rating'] = rating['rating'].values.astype(np.float32)

min_rating = min(rating['rating'])
max_rating = max(rating['rating'])
 
print('Number of User: {}, Number of Book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""## Train-Test-Split

Acak terlebih dahulu data
"""

rating = rating.sample(frac=1, random_state=42)
rating

"""Selanjutnya bagi data training menjadi 70% serta data test menjadi 30%"""

x = rating[['user', 'book']].values
 
y = rating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
train_indices = int(0.70 * rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""## Modelling

Mengimpor modul
"""

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf

"""Di sini, saya membuat class RecommenderNet dengan keras Model class."""

class RecommenderNet(tf.keras.Model):
 
  def __init__(self, num_users, num_book, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_book = num_book
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.book_embedding = layers.Embedding( 
        num_book,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_book, 1) 
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1]) 
 
    dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
 
    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x)

"""Lakukan Kompilasi terhadap model"""

model = RecommenderNet(num_users, num_book, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Melakukan Training"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 5,
    epochs = 20,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Plot Mean Squared Error')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Mendapatkan rekomendasi

Definisikan kembali dataset book dan rating
"""

book =  new_book
rating = rating

"""Ambil user_id secara acak pada dataset rating, lalu cek untuk mengetahui buku yang telah dibaca dan yang belum dibaca sehingga rekomendasinya nanti berisi buku-buku yang belum pernah dibaca sebelumnya"""

user_id = rating.user_id.sample(1).iloc[0]
books_have_been_read_by_user = rating[rating.user_id == user_id]
 
books_have_not_been_read_by_user = book[book['book_ISBN'].isin(books_have_been_read_by_user.ISBN.values)]['book_ISBN'] 
books_have_not_been_read_by_user = list(
    set(books_have_not_been_read_by_user)
    .intersection(set(book_to_book_encoded.keys()))
)
 
books_have_not_been_read_by_user = [[book_to_book_encoded.get(x)] for x in books_have_not_been_read_by_user]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(books_have_not_been_read_by_user), books_have_not_been_read_by_user)
)

ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(books_have_not_been_read_by_user[x][0]) for x in top_ratings_indices
]
 
top_books_recommended = (
    books_have_been_read_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
books_row = book[book['book_ISBN'].isin(top_books_recommended)]
for row in books_row.itertuples():
    print(row.book_title, ':', row.book_author)
 
print('----' * 8)
print('Top 10 Book Recommendation for user: {}'.format(user_id))
print('----' * 8)
 
recommended_books = book[book['book_ISBN'].isin(recommended_book_ids)]
for row in recommended_books.itertuples():
    print(row.book_title, ':', row.book_author)